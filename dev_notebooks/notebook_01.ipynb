{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "- Why are you using machine learning rather than a simpler approach?\n",
    "- What is it about the problem/data that is suitable for logistic regression? \n",
    "- Objective: \n",
    "  - Predict which customers who will \"churn\" (leave a business service), given the data in our training set associated with each subscriber to SyriaTel's phone plan. This way we can identify these customers before they churn, which will hopefully allow us to find ways to retain them before they leave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "| -------- | -------- | -------- |  \n",
    "| churn | Has customer ceased doing business with SyriaTel | False = has not churned, True = has churned \n",
    "| state | US State | |\n",
    "| account length | Num digits: indicates account age | |\n",
    "| area code | Phone number area code | |\n",
    "| phone number | Phone number | |\n",
    "| international plan | Customer has intl. plan | 'yes', 'no' |\n",
    "| voice mail plan | Customer has voice mail plan | 'yes', 'no'|\n",
    "| number vmail messages | | | |\n",
    "| total day minutes\n",
    "| total day calls\n",
    "| total day charge\n",
    "| total eve minutes\n",
    "| total eve calls\n",
    "| total eve charge\n",
    "| total night minutes\n",
    "| total night calls\n",
    "| total night charge\n",
    "| total intl minutes\n",
    "| total intl calls\n",
    "| total intl charge\n",
    "| customer service calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data and Import Libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Python Libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# plot_confusion_matrix is a handy visual tool, added in the latest version of scikit-learn\n",
    "# if you are running an older version, comment out this line and just use confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data:\n",
    "df = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account length  area code phone number international plan  \\\n",
       "0    KS             128        415     382-4657                 no   \n",
       "1    OH             107        415     371-7191                 no   \n",
       "2    NJ             137        415     358-1921                 no   \n",
       "3    OH              84        408     375-9999                yes   \n",
       "4    OK              75        415     330-6626                yes   \n",
       "\n",
       "  voice mail plan  number vmail messages  total day minutes  total day calls  \\\n",
       "0             yes                     25              265.1              110   \n",
       "1             yes                     26              161.6              123   \n",
       "2              no                      0              243.4              114   \n",
       "3              no                      0              299.4               71   \n",
       "4              no                      0              166.7              113   \n",
       "\n",
       "   total day charge  ...  total eve calls  total eve charge  \\\n",
       "0             45.07  ...               99             16.78   \n",
       "1             27.47  ...              103             16.62   \n",
       "2             41.38  ...              110             10.30   \n",
       "3             50.90  ...               88              5.26   \n",
       "4             28.34  ...              122             12.61   \n",
       "\n",
       "   total night minutes  total night calls  total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   total intl minutes  total intl calls  total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   customer service calls  churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>101.064806</td>\n",
       "      <td>437.182418</td>\n",
       "      <td>8.099010</td>\n",
       "      <td>179.775098</td>\n",
       "      <td>100.435644</td>\n",
       "      <td>30.562307</td>\n",
       "      <td>200.980348</td>\n",
       "      <td>100.114311</td>\n",
       "      <td>17.083540</td>\n",
       "      <td>200.872037</td>\n",
       "      <td>100.107711</td>\n",
       "      <td>9.039325</td>\n",
       "      <td>10.237294</td>\n",
       "      <td>4.479448</td>\n",
       "      <td>2.764581</td>\n",
       "      <td>1.562856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.822106</td>\n",
       "      <td>42.371290</td>\n",
       "      <td>13.688365</td>\n",
       "      <td>54.467389</td>\n",
       "      <td>20.069084</td>\n",
       "      <td>9.259435</td>\n",
       "      <td>50.713844</td>\n",
       "      <td>19.922625</td>\n",
       "      <td>4.310668</td>\n",
       "      <td>50.573847</td>\n",
       "      <td>19.568609</td>\n",
       "      <td>2.275873</td>\n",
       "      <td>2.791840</td>\n",
       "      <td>2.461214</td>\n",
       "      <td>0.753773</td>\n",
       "      <td>1.315491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.700000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>24.430000</td>\n",
       "      <td>166.600000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>14.160000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.520000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>179.400000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>201.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.120000</td>\n",
       "      <td>201.200000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>127.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>216.400000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>36.790000</td>\n",
       "      <td>235.300000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>235.300000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>10.590000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>350.800000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>59.640000</td>\n",
       "      <td>363.700000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>30.910000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>17.770000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       account length    area code  number vmail messages  total day minutes  \\\n",
       "count     3333.000000  3333.000000            3333.000000        3333.000000   \n",
       "mean       101.064806   437.182418               8.099010         179.775098   \n",
       "std         39.822106    42.371290              13.688365          54.467389   \n",
       "min          1.000000   408.000000               0.000000           0.000000   \n",
       "25%         74.000000   408.000000               0.000000         143.700000   \n",
       "50%        101.000000   415.000000               0.000000         179.400000   \n",
       "75%        127.000000   510.000000              20.000000         216.400000   \n",
       "max        243.000000   510.000000              51.000000         350.800000   \n",
       "\n",
       "       total day calls  total day charge  total eve minutes  total eve calls  \\\n",
       "count      3333.000000       3333.000000        3333.000000      3333.000000   \n",
       "mean        100.435644         30.562307         200.980348       100.114311   \n",
       "std          20.069084          9.259435          50.713844        19.922625   \n",
       "min           0.000000          0.000000           0.000000         0.000000   \n",
       "25%          87.000000         24.430000         166.600000        87.000000   \n",
       "50%         101.000000         30.500000         201.400000       100.000000   \n",
       "75%         114.000000         36.790000         235.300000       114.000000   \n",
       "max         165.000000         59.640000         363.700000       170.000000   \n",
       "\n",
       "       total eve charge  total night minutes  total night calls  \\\n",
       "count       3333.000000          3333.000000        3333.000000   \n",
       "mean          17.083540           200.872037         100.107711   \n",
       "std            4.310668            50.573847          19.568609   \n",
       "min            0.000000            23.200000          33.000000   \n",
       "25%           14.160000           167.000000          87.000000   \n",
       "50%           17.120000           201.200000         100.000000   \n",
       "75%           20.000000           235.300000         113.000000   \n",
       "max           30.910000           395.000000         175.000000   \n",
       "\n",
       "       total night charge  total intl minutes  total intl calls  \\\n",
       "count         3333.000000         3333.000000       3333.000000   \n",
       "mean             9.039325           10.237294          4.479448   \n",
       "std              2.275873            2.791840          2.461214   \n",
       "min              1.040000            0.000000          0.000000   \n",
       "25%              7.520000            8.500000          3.000000   \n",
       "50%              9.050000           10.300000          4.000000   \n",
       "75%             10.590000           12.100000          6.000000   \n",
       "max             17.770000           20.000000         20.000000   \n",
       "\n",
       "       total intl charge  customer service calls  \n",
       "count        3333.000000             3333.000000  \n",
       "mean            2.764581                1.562856  \n",
       "std             0.753773                1.315491  \n",
       "min             0.000000                0.000000  \n",
       "25%             2.300000                1.000000  \n",
       "50%             2.780000                1.000000  \n",
       "75%             3.270000                2.000000  \n",
       "max             5.400000                9.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   3333 non-null   object \n",
      " 1   account length          3333 non-null   int64  \n",
      " 2   area code               3333 non-null   int64  \n",
      " 3   phone number            3333 non-null   object \n",
      " 4   international plan      3333 non-null   object \n",
      " 5   voice mail plan         3333 non-null   object \n",
      " 6   number vmail messages   3333 non-null   int64  \n",
      " 7   total day minutes       3333 non-null   float64\n",
      " 8   total day calls         3333 non-null   int64  \n",
      " 9   total day charge        3333 non-null   float64\n",
      " 10  total eve minutes       3333 non-null   float64\n",
      " 11  total eve calls         3333 non-null   int64  \n",
      " 12  total eve charge        3333 non-null   float64\n",
      " 13  total night minutes     3333 non-null   float64\n",
      " 14  total night calls       3333 non-null   int64  \n",
      " 15  total night charge      3333 non-null   float64\n",
      " 16  total intl minutes      3333 non-null   float64\n",
      " 17  total intl calls        3333 non-null   int64  \n",
      " 18  total intl charge       3333 non-null   float64\n",
      " 19  customer service calls  3333 non-null   int64  \n",
      " 20  churn                   3333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 524.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts on Data (Consider the business problem when choosing features)\n",
    "- Area codes (and by associate phone numbers) and State do not match (415 is not an area code in Kansas)\n",
    "- \"State\" may be a useful geographical feature to consider, but lots of people live in states that don't match their phone #'s area code, so area code isn't a reliable indicator of location.\n",
    "- There are no nulls\n",
    "- Categorical Variables (besides target which is Churn)\n",
    "- ## Numeric vs. Categorical:\n",
    "  - Is it numeric or categorical?\n",
    "    - As \"Is an increase of 2 in this variable twice as much as an increase of 1?\"\n",
    "  - State\n",
    "- These are boolean value columns - so they don't need to be one-hot-encoded, just converted from yes/no to 1/0\n",
    "  - international plan\n",
    "  - voice mail plan\n",
    "- Ordinal values -- there are none\n",
    "- To Drop:\n",
    "  -   Area Code (because an increase of 1 does'nt mean twice as many)\n",
    "  -   Phone number (because an increase of 1 does'nt mean twice as many)\n",
    "- Calls vs. Minutes\n",
    "  - The more calls doesn't necessarily mean more minutes, so we will keep calls and minutes (they are not redundant)\n",
    "  \n",
    "### Ideas for later:\n",
    "- How could we tease apart \"international plan\" and \"total intl calls\"/minutes in order to see how likely a customer with a high number of international minutes but no international plan is likely to churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "- Pattern of error?\n",
    "\n",
    "- Cannabilize the violin plot function in here for EDA:\n",
    "  - 41-classification_workflow-completed.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose most important features by finding ones highest correlated with target:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See if people with no international plan and high international minutes/calls is more or less likely to churn\n",
    "- Is no intl. plan correlated + high minutes correlated to churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIVE! Eyes on the Prize!\n",
    "- Predictive Findings:\n",
    "  - How well your model is able to predict target\n",
    "  - Which features are most important to model\n",
    "- Predictive Recommendations:\n",
    "  - Context and situation where predictions would be useful\n",
    "  - Suggest to data engineers how data can be transformed upon ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test/Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Iterative Modeling Process:\n",
    "1. Dummy model\n",
    "2. Evaluate on appropriate classification metrics (bias/variance?)\n",
    "3. Proceed to next model (provide justification!)\n",
    "- Ultimate Goal is to Create a classifier that beats dummy model - doesn't have to be perfect\n",
    "  - When your model isn't improving and you've tuned a couple, you can stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Modeling Process us Cross-Validation:\n",
    "### Process below is from this lecture (also has lots on how to appropriately use Regularization): ***36-Regularization_Lecture-completed.ipynb***\n",
    "\n",
    "So, now our modeling process has an added step: cross-validation.\n",
    "\n",
    "1. Get Data\n",
    "2. EDA\n",
    "3. Cleaning\n",
    "4. Feature Engineering\n",
    "5. Train/Test split\n",
    "6. Model training using `train` split\n",
    "7. Cross Validation (Once you are happy with the model, then do step 8)\n",
    "8. Model testing using `test` split\n",
    "\n",
    "Please note, this is **NOT** a linear process.\n",
    "\n",
    "You will repeat steps 3 through 7 many times. \n",
    "\n",
    "You only use the `test` split when you are satisfied of your model's performance as judged by the cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See this lecture for example of entire logistic regression (classification) workflow:\n",
    "### **41-classification_workflow-completed.ipynb**\n",
    "- Adapt the \"\"ModelwithCV\" class\" thingie - an copy it but just cite source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Viable Product:\n",
    "- Use logistic regression, no need for any other algorithm\n",
    "- Fit the transformer on the training data and use it to transform both the train and test\n",
    "- Never fit anything to test\n",
    "- Don't use target as a feature or a numeric target\n",
    "- Don't REDUCE regularization on a model that is overfitting. INCREASE regularization if model is overfitting.\n",
    "- Report the model's performance on the TEST data, not the training data.\n",
    "- Tune at least 1 hyperparameter in a justifiable way without any major errors\n",
    "- Focus on specific metrics that are important to business case (not just displaying `classification_report` and/or confusion matrix -- you wouldn't want to try and discuss ALL evaluation metrics, and you also wouldn't want to just display the metrics without discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Model & Initial feature selection:\n",
    "1. Choosing features is indeed an iterative process. For the dummy model in logistic regression, it's simply predicting the majority class. For logistic regression, which is a type of linear model, you can use all columns to start out with or take the top 3-5 columns most correlated with the target. For subsequent iterative models, can choose different cols. If model is underfit, can increase complexity (variance) with polynomial features. If overfit, good approach is increasing regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "- Evaluate based on TEST data\n",
    "- Bias/Variance - overfitting vs. underfitting\n",
    "- Recall\n",
    "- Precision\n",
    "- Accuracy\n",
    "- MSE (better than R-squared for explaining to stakeholders)\n",
    "- Confusion Matrix\n",
    "- `classification_report`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning! Make justifiable changes in successive models:\n",
    "- DO NOT reduce regularization on a model that is overfitting.\n",
    "  - Regularization parameter (lambda) penalizes all the parameters except intercept so that model generalizes the data and won’t overfit.\n",
    "- Threshold: Calculate from ROC Curve:\n",
    "  - https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "- Tune Hyperparameters and Grid Search:\n",
    "  - https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/\n",
    "- Manipulate target?\n",
    "- Maximize validation scores\n",
    "  - As a validation score, accuracy is inappropriate for imbalanced classification problems\n",
    "  - Use precision, recall, F-Measure for imbalanced classification: https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/\n",
    "- Cross validation: https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation/\n",
    "- Consider Bias/Variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "- After refining models, provide 1-3 paragraphs discussing final model and at least 1 overall model metric\n",
    "- Model Limitations Discussion:\n",
    "  - Records/Instances where model performance was worse (Question: Does this mean an individual row?)\n",
    "  - If used in production, what kinds of problems would pop up?\n",
    "  - Connect metrics to real-world implications \n",
    "    - What should stakeholders do with this information?\n",
    "\n",
    "This can include rows/individuals in training set that are outliers - maybe your model performs especially bad on those. Basically, the \"limitations\" part of your final discussion should address weaknesses in data and algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional:\n",
    "- Cross Validation\n",
    "- Feature Engineering\n",
    "- Pipelines\n",
    "  - Only use pipelines later if you have time\n",
    "  - Pipelines help prevent data leakage\n",
    "  - They transform the test set exactly how train was transformed\n",
    "  - Pipelines are the best-practice approach to data preparation that avoids leakage, but they can get complicated very quickly. We therefore do not recommend that you use pipelines in your initial modeling approach, but rather that you refactor to use pipelines if you have time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
